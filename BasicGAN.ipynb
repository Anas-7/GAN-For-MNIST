{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\n",
    "    # The view command is used to modify the dimensions of the image. Here we flatten the images.\n",
    "    image_unflat = image_tensor.detach().cpu().view(-1, *size)\n",
    "    # The grid details are similar to MNIST image dimensions\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dimensions of the image prior to the execution\n",
    "# n_channels is 1 for grayscale images and 3 for RGB images.\n",
    "n_channels = 1\n",
    "# Dimensions of images in MNIST\n",
    "basewidth = 28\n",
    "baseheight = 28\n",
    "\n",
    "# Print the name of GPU and set it as the default device for tensor operations\n",
    "print(torch.cuda.get_device_name(0))\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to create a generator which inherits from the parent class nn.Module\n",
    "class Generator(nn.Module):\n",
    "    #Here dist_size represents the size of the distribution which will be used to generate the image(s).\n",
    "    def __init__(self, dist_size = 10, base_hidden_units = 128, basewidth = 28, baseheight = 28, n_channels = 1):\n",
    "        super(Generator, self).__init__()\n",
    "        self.dist_size = dist_size\n",
    "        self.base_hidden_units = base_hidden_units\n",
    "        #Define the size of the image as the product of its dimensions\n",
    "        self.final_img_size = basewidth * baseheight * n_channels\n",
    "        #Define the generator as a sequential block which in itself contains a generalised block.\n",
    "        self.gen = nn.Sequential(\n",
    "            #Generator needs to be dense\n",
    "            self.make_genblock(dist_size, base_hidden_units),\n",
    "            self.make_genblock(base_hidden_units, base_hidden_units * 2),\n",
    "            self.make_genblock(base_hidden_units * 2, base_hidden_units * 4),\n",
    "            self.make_genblock(base_hidden_units * 4, base_hidden_units * 8),\n",
    "            nn.Linear(base_hidden_units * 8,self.final_img_size),\n",
    "            #The output is restricted to values between 0 and 1 using Sigmoid. TanH can be experimented with as well\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, noise_vecs):\n",
    "        return self.gen(noise_vecs)\n",
    "    #This is a basic process for hidden layer.\n",
    "    def make_genblock(self, input_units, output_units):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(input_units,output_units),\n",
    "            nn.BatchNorm1d(output_units),\n",
    "            # This works better than normal ReLu (atleast for 200 iterations)\n",
    "            nn.LeakyReLU(0.01,inplace=True)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to create a discriminator which inherits from the parent class nn.Module\n",
    "# Its very similar to the Generator class\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, base_hidden_units = 128, basewidth = 28, baseheight = 28, n_channels = 1):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.base_hidden_units = base_hidden_units\n",
    "        self.input_img_size = basewidth * baseheight * n_channels\n",
    "        #Since this acts as a classifying model, we use a model decreasing in size\n",
    "        #as it can then be trained faster.\n",
    "        self.disc = nn.Sequential(\n",
    "            self.make_discblock(self.input_img_size, base_hidden_units * 4),\n",
    "            self.make_discblock(base_hidden_units * 4, base_hidden_units * 2),\n",
    "            self.make_discblock(base_hidden_units * 2, base_hidden_units),\n",
    "            #Since the inputs are between 0 and 1, a sigmoid is unnecessary.\n",
    "            #A function to strictly restrict the values between 0 and 1 can be used for surety.\n",
    "            nn.Linear(base_hidden_units, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, images):\n",
    "        return self.disc(images)\n",
    "    #Here LeakyReLu is used since if the values reach zero then the training is impacted.\n",
    "    def make_discblock(self, input_units, output_units):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(input_units, output_units),\n",
    "            # Batch Norm should not be used since the mean distribution would consist of real and fake images during training\n",
    "            # while the distribution of images during test time will be of fake images only.\n",
    "            nn.LeakyReLU(0.2, inplace = True)\n",
    "# You have to look at the basics of batchnorm to understand what is happening. At train time, the layer aggregates an average mean\n",
    "# called VAR but trains on that batch’s metrics. At test time, the aggregated weights (mean and variance) are used on the input.\n",
    "\n",
    "# When training the discriminator, batchnorm uses the real and fake batch to normalize. The moving average of the batchnorm will aggregate\n",
    "# both distributions. If your batch has a mix of both, the mean at each batch will be similar to the moving average.\n",
    "\n",
    "# Otherwise, you will have 3 completely different values: one for real samples, one for fake samples, one for moving average (which is the one used at test time).\n",
    "# Let’s look at what happens at test time (i.e. the generator loss): your input is fake, and the batchnorm is using a normalization based on both real and fake samples. This is very different from what you were seeing at training time if you had full batches of either real or fake samples. And, being different, the backpropagation from D is now not that meaningful…\n",
    "# Long story short: make sure your batchnorm weights are consistent at train and test, or don’t use it at all.\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for return values of input sampled from standard normal distribution.\n",
    "def generate_noise(num_images, dist_size):\n",
    "    return torch.randn(num_images, dist_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the hyperparameters\n",
    "lr = 0.00005\n",
    "dist_size = 64\n",
    "batch_size = 128\n",
    "epochs = 200\n",
    "cur_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the MNIST dataset\n",
    "# pin_memory = True didnt work for my GPU. Changing num_workers to a value > 0 yields no significant benefit\n",
    "dataloader = DataLoader(\n",
    "    MNIST('.', download=True, transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The loss function is binary cross entropy\n",
    "# If the correct value is y and predicted value is y_pred then,\n",
    "# The loss for one image is defined as loss = -(y * log (y_pred) + (1 - y) * log (1 - y_pred))\n",
    "bceLoss = nn.BCEWithLogitsLoss()\n",
    "# The objects which are to be trained\n",
    "generator = Generator(dist_size = dist_size)\n",
    "discriminator = Discriminator()\n",
    "# The optimisers for applying gradient descent. SGD can be used as well\n",
    "generator_opt = torch.optim.Adam(generator.parameters(),lr=lr)\n",
    "discriminator_opt = torch.optim.Adam(discriminator.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "\n",
    "    # Dataloader returns the batches\n",
    "    for real, _ in tqdm(dataloader):\n",
    "        cur_batch_size = len(real)\n",
    "\n",
    "        # Using the view method to flatten the images in the form of a vector\n",
    "        real = real.view(cur_batch_size, -1)\n",
    "\n",
    "        # Reset the gradients before every training loop to prevent accumulation of gradients from previous iterations.\n",
    "        # A proper explanantion is availaible on the link below\n",
    "        # https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch\n",
    "        discriminator_opt.zero_grad()\n",
    "\n",
    "        # Calculate performance of the discriminator on detecting fake images\n",
    "        # Get the input vectors\n",
    "        disc_inputs = generate_noise(cur_batch_size, dist_size)\n",
    "        # Store the outputs provided by the generator.\n",
    "        # Keep in mind that disc_inputs and generator are part of the computation graph.\n",
    "        disc_generator_outputs = generator(disc_inputs)\n",
    "        #IMPORTANT: This step is necessary as we dont want the backpropagation to affect the weights of the generator\n",
    "        # This can occur as the generator is part of the computation graph, which is why we detach disc_generator_outputs\n",
    "        # The backpropagation will now be considered to end at the disc_fake_outputs. Check the link below for detach function with visualisation\n",
    "        # http://www.bnikolic.co.uk/blog/pytorch-detach.html\n",
    "        disc_fake_outputs = discriminator(disc_generator_outputs.detach())\n",
    "        # We want the discrimator to be penalised if it doesnt predict value = 0 for fake images\n",
    "        disc_fake_loss = bceLoss(disc_fake_outputs, torch.zeros_like(disc_fake_outputs))\n",
    "        \n",
    "        # Calculate performance of the discriminator on recognising real images\n",
    "        # Store the outputs of the discriminator.\n",
    "        disc_real_outputs = discriminator(real)\n",
    "        # We want the discrimator to be penalised if it doesnt predict value = 1 for real images.\n",
    "        disc_real_loss = bceLoss(disc_real_outputs, torch.ones_like(disc_real_outputs))\n",
    "        #Take the average of the loss\n",
    "        discriminator_loss = (disc_real_loss + disc_fake_loss)/2\n",
    "\n",
    "        # Get the gradients of the discriminator.\n",
    "        discriminator_loss.backward(retain_graph=True)\n",
    "        # Perform the gradient descent using the gradients of the previous step.\n",
    "        discriminator_opt.step()\n",
    "\n",
    "        # Reset the gradients\n",
    "        generator_opt.zero_grad()\n",
    "        # Calculate performance of the generator on fooling the discriminator.\n",
    "        # Get the input vectors\n",
    "        gen_inputs = generate_noise(cur_batch_size, dist_size)\n",
    "        # Store the outputs provided by the generator.\n",
    "        gen_outputs = generator(gen_inputs)\n",
    "        # Store the results of discriminator checking the generated images.\n",
    "        gen_disc_outputs = discriminator(gen_outputs)\n",
    "        # We want the generator to be penalised if the discriminator gives a value = 0, i.e., detects the image is generated.\n",
    "        gen_loss = bceLoss(gen_disc_outputs, torch.ones_like(gen_disc_outputs))\n",
    "        # Get the gradients of the generator.\n",
    "        gen_loss.backward(retain_graph=True)\n",
    "        # Perform the gradient descent using the gradients of the previous step.\n",
    "        # Even though the discriminator is part of the computation graph and hence the backpropagagtion, we only update weights of generator.\n",
    "        generator_opt.step()\n",
    "\n",
    "        if cur_step % 150 == 0:\n",
    "            print(f\"Epoch {epoch}, step {cur_step}\")\n",
    "            fake_noise = generate_noise(cur_batch_size, dist_size)\n",
    "            fake = generator(fake_noise)\n",
    "            show_tensor_images(fake)\n",
    "            show_tensor_images(real)\n",
    "        cur_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the generator model\n",
    "import pickle\n",
    "filename = 'generator_local_leakyRelu_pickled.pkl'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(generator,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model to check whether it works or not\n",
    "infile = open(filename,'rb')\n",
    "generator_local_pickled = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check output generated or not\n",
    "show_tensor_images(generator_local_pickled(generate_noise(25,64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
